{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tdt-xed-neutral-comparison.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6268d1e3cf19470f8fb075500b029a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4eb9d9ff3fe436d856e3b7a990fb87a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6de144b2850b46f4956b67f38c92966d",
              "IPY_MODEL_4ee0436fdd824dd8b517223cffbe3c3c"
            ]
          }
        },
        "c4eb9d9ff3fe436d856e3b7a990fb87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6de144b2850b46f4956b67f38c92966d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68fa4330762a4f319da25cb8c1dcceab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88ec2888e1514dca92f91375e887410c"
          }
        },
        "4ee0436fdd824dd8b517223cffbe3c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43e4671e55e14e32bd984d8057ae86c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 482B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e08b2d80b7e3479993d245df228c5933"
          }
        },
        "68fa4330762a4f319da25cb8c1dcceab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88ec2888e1514dca92f91375e887410c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43e4671e55e14e32bd984d8057ae86c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e08b2d80b7e3479993d245df228c5933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb6387759e2a4e4b959d661badb3fcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60abe4365b0c42a28f7db9e2fba11008",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e90d1113c9a4b40a149173fd0ab290f",
              "IPY_MODEL_1b4bbf44c44e461f9e59d2e331848772"
            ]
          }
        },
        "60abe4365b0c42a28f7db9e2fba11008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e90d1113c9a4b40a149173fd0ab290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6487fe574fab478ab52bb04f6633c4b0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 656434900,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 656434900,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c03e3f5f00049dd89a9665102367321"
          }
        },
        "1b4bbf44c44e461f9e59d2e331848772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca004d0994a14826906940c7eaf46ec3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 656M/656M [00:23&lt;00:00, 28.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b2de5651ce44c3181b67e0e5228999d"
          }
        },
        "6487fe574fab478ab52bb04f6633c4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c03e3f5f00049dd89a9665102367321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca004d0994a14826906940c7eaf46ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b2de5651ce44c3181b67e0e5228999d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5mae7Zqv2H-"
      },
      "source": [
        "This notebook compares two identical models trained with different data: One with Anger and Joy classes from XED and neutrals also from XED, and the other with the same classes from XED but neutrals from TDT. Both models use FinBERT with TFBertForSequenceClassification from Huggingface Transformers. The trained models are then compared with in-domain data as well as out-of-domain data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex1PD3JOvGXv"
      },
      "source": [
        "# Set the file paths here\r\n",
        "tdt_train_fn = '/content/tdt-sentiment-151020-train-clean.tsv'\r\n",
        "tdt_eval_fn = '/content/tdt-sentiment-151020-dev.tsv'\r\n",
        "xed_nonneutrals_fn = '/content/fi-annotated.tsv'\r\n",
        "xed_neutrals_fn = '/content/neu_fi.txt'\r\n",
        "twitter_and_s24_fn = '/content/twitter-and-s24-sentences.tsv'\r\n",
        "\r\n",
        "# Output file paths\r\n",
        "disagreement_fn = '/content/tdt_xed_disagreement_ood.tsv'\r\n",
        "probabilities_fn = '/content/tdt_xed_probabilities_ood.tsv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rtq9Mg7gdU4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AbeqiZYgjbT"
      },
      "source": [
        "# Choose model and set up input\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizerFast\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "def transpose(l):\n",
        "  return [list(t) for t in zip(*l)]\n",
        "\n",
        "def load_fields(fn):\n",
        "  return transpose([l.rstrip('\\n').split('\\t') for l in open(fn).readlines()])\n",
        "\n",
        "def label_vector(num_labels, labels):\n",
        "  binary_labels = []\n",
        "  for ls in labels:\n",
        "    b = [0]*num_labels\n",
        "    for l in ls:\n",
        "      b[l] = 1\n",
        "    binary_labels.append(b)\n",
        "  return binary_labels\n",
        "\n",
        "tdt_train_texts, tdt_train_labels_raw = load_fields(tdt_train_fn)[1:3]\n",
        "tdt_eval_texts, tdt_eval_labels_raw = load_fields(tdt_eval_fn)[1:3]\n",
        "\n",
        "nonneutral_texts, nonneutral_labels_raw = load_fields(xed_nonneutrals_fn)[:2]\n",
        "xed_neutral_texts_full = load_fields(xed_neutrals_fn)[1]\n",
        "\n",
        "nonneutral_labels = [[int(s) for s in l.replace('8', '0').split(',')] for l in nonneutral_labels_raw]\n",
        "\n",
        "nonneutral_classes = {1, 5}\n",
        "encoded_to_index = dict(enumerate(nonneutral_classes))\n",
        "index_to_encoded = {v: k for k, v in encoded_to_index.items()}\n",
        "index_to_name = dict(enumerate(['trust', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise']))\n",
        "num_labels = len(nonneutral_classes)\n",
        "\n",
        "chosen_nonneutral_texts, chosen_nonneutral_labels = transpose([[t, l] for t, l in zip(nonneutral_texts, nonneutral_labels) if set(l) <= nonneutral_classes])\n",
        "\n",
        "train_neutral_texts, train_neutral_label_vectors = transpose([[t, [0]*num_labels] for t, l in zip(tdt_train_texts, tdt_train_labels_raw) if l == 'neutral'])\n",
        "eval_neutral_texts, eval_neutral_label_vectors = transpose([[t, [0]*num_labels] for t, l in zip(tdt_eval_texts, tdt_eval_labels_raw) if l == 'neutral'])\n",
        "\n",
        "# Undersample the XED neutrals so that the number of neutral examples is equal between the models.\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "xed_neutral_texts = random.sample(xed_neutral_texts_full, len(train_neutral_texts) + len(eval_neutral_texts))\n",
        "xed_neutral_label_vectors = [[0]*num_labels]*len(xed_neutral_texts)\n",
        "\n",
        "chosen_nonneutral_label_vectors = label_vector(num_labels, [[index_to_encoded[e] for e in l] for l in chosen_nonneutral_labels])\n",
        "\n",
        "train_nonneutral_texts, eval_nonneutral_texts, train_nonneutral_label_vectors, eval_nonneutral_label_vectors = train_test_split(chosen_nonneutral_texts, chosen_nonneutral_label_vectors, test_size=0.1, random_state=seed)\n",
        "xed_train_neutral_texts, xed_eval_neutral_texts, xed_train_neutral_label_vectors, xed_eval_neutral_label_vectors = train_test_split(xed_neutral_texts, xed_neutral_label_vectors, test_size=len(eval_neutral_texts), random_state=seed)\n",
        "\n",
        "train_texts = train_neutral_texts + train_nonneutral_texts\n",
        "train_label_vectors = tf.constant(train_neutral_label_vectors + train_nonneutral_label_vectors, dtype='float32')\n",
        "\n",
        "eval_texts = eval_neutral_texts + eval_nonneutral_texts\n",
        "eval_label_vectors = tf.constant(eval_neutral_label_vectors + eval_nonneutral_label_vectors, dtype='float32')\n",
        "\n",
        "#model_name = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
        "model_name = \"TurkuNLP/bert-base-finnish-uncased-v1\"\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "input_size = 128\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding='longest', max_length=input_size)\n",
        "eval_encodings = tokenizer(eval_texts, truncation=True, padding='longest', max_length=input_size)\n",
        "\n",
        "t = [tf.constant(train_encodings.data[s]) for s in ['input_ids', 'attention_mask', 'token_type_ids']]\n",
        "e = [tf.constant(eval_encodings.data[s]) for s in ['input_ids', 'attention_mask', 'token_type_ids']]\n",
        "\n",
        "xed_train_texts = xed_train_neutral_texts + train_nonneutral_texts\n",
        "xed_eval_texts = xed_eval_neutral_texts + eval_nonneutral_texts\n",
        "xed_train_label_vectors = tf.constant(xed_train_neutral_label_vectors + train_nonneutral_label_vectors, dtype='float32')\n",
        "xed_eval_label_vectors = tf.constant(xed_eval_neutral_label_vectors + eval_nonneutral_label_vectors, dtype='float32')\n",
        "\n",
        "xed_train_encodings = tokenizer(xed_train_texts, truncation=True, padding='longest', max_length=input_size)\n",
        "xed_eval_encodings = tokenizer(xed_eval_texts, truncation=True, padding='longest', max_length=input_size)\n",
        "\n",
        "t_xed = [tf.constant(xed_train_encodings.data[s]) for s in ['input_ids', 'attention_mask', 'token_type_ids']]\n",
        "e_xed = [tf.constant(xed_eval_encodings.data[s]) for s in ['input_ids', 'attention_mask', 'token_type_ids']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEZdXV4t6jFk"
      },
      "source": [
        "# Set up training\n",
        "from transformers import TFBertForSequenceClassification, optimization_tf\n",
        "\n",
        "init_lr = 2e-5\n",
        "\n",
        "epochs = 2\n",
        "batch_size_train = 16\n",
        "batch_size_eval = 16\n",
        "\n",
        "def train(model, t, train_labels, eval):\n",
        "  size_train = len(train_labels)\n",
        "  steps_per_epoch = int(size_train/batch_size_train)\n",
        "  steps_train = steps_per_epoch*epochs\n",
        "  steps_warmup = int(epochs * size_train * 0.1 / batch_size_train)\n",
        "  optimizer, _ = optimization_tf.create_optimizer(init_lr=init_lr,\n",
        "                                                  num_train_steps=steps_train,\n",
        "                                                  num_warmup_steps=steps_warmup,\n",
        "                                                  weight_decay_rate=0.01)\n",
        "  model.compile(optimizer=optimizer, loss=tf.nn.sigmoid_cross_entropy_with_logits, metrics=[])\n",
        "  model.fit(t,\n",
        "            train_labels,\n",
        "            validation_data=eval,\n",
        "            batch_size=batch_size_train,\n",
        "            epochs=epochs)\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSWzWPns6qEq"
      },
      "source": [
        "# Set up evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def train_evaluate(train_x, train_y, eval_x, eval_y, num_labels, run_count):\n",
        "  runs = []\n",
        "  for i in range(run_count):\n",
        "    bert = TFBertForSequenceClassification.from_pretrained(model_name,\n",
        "                                                           num_labels=num_labels)\n",
        "    bert = train(bert, train_x, train_y, (eval_x, eval_y))\n",
        "    runs.append(bert.predict(eval_x)[0])\n",
        "  return runs\n",
        "\n",
        "def format_floats(l):\n",
        "  return ', '.join(f'{x:.4f}' for x in l)\n",
        "\n",
        "def print_results(runs, eval_label_vectors):\n",
        "  preds = [(tf.math.sigmoid(r) >= 0.5).numpy().tolist() for r in runs]\n",
        "  accuracy = [accuracy_score(eval_label_vectors, p) for p in preds]\n",
        "  weighted_f1 = [f1_score(eval_label_vectors, p, average='weighted') for p in preds]\n",
        "  print(f\"Accuracy: {format_floats(accuracy)}\")\n",
        "  print(f\"Weighted F-score: {format_floats(weighted_f1)}\")\n",
        "  print(f'Average accuracy: {np.mean(accuracy):.4f}, stdev: {np.std(accuracy):.4f}')\n",
        "  print(f'Average weighted F-score: {np.mean(weighted_f1):.4f}, stdev: {np.std(weighted_f1):.4f}')\n",
        "  max_i = accuracy.index(max(accuracy))\n",
        "  print(classification_report(eval_label_vectors, preds[max_i], target_names=[index_to_name[encoded_to_index[i]] for i in range(num_labels)], digits=4))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQzfDmPJF8UX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6268d1e3cf19470f8fb075500b029a83",
            "c4eb9d9ff3fe436d856e3b7a990fb87a",
            "6de144b2850b46f4956b67f38c92966d",
            "4ee0436fdd824dd8b517223cffbe3c3c",
            "68fa4330762a4f319da25cb8c1dcceab",
            "88ec2888e1514dca92f91375e887410c",
            "43e4671e55e14e32bd984d8057ae86c8",
            "e08b2d80b7e3479993d245df228c5933",
            "cb6387759e2a4e4b959d661badb3fcc8",
            "60abe4365b0c42a28f7db9e2fba11008",
            "2e90d1113c9a4b40a149173fd0ab290f",
            "1b4bbf44c44e461f9e59d2e331848772",
            "6487fe574fab478ab52bb04f6633c4b0",
            "1c03e3f5f00049dd89a9665102367321",
            "ca004d0994a14826906940c7eaf46ec3",
            "9b2de5651ce44c3181b67e0e5228999d"
          ]
        },
        "outputId": "559fbd5c-774e-4c9b-f9b4-9a2f327fb56e"
      },
      "source": [
        "# Evaluate with in-domain data\n",
        "\n",
        "runs_tdt = train_evaluate(t, train_label_vectors, e, eval_label_vectors, num_labels, 5)\n",
        "runs_xed = train_evaluate(t_xed, xed_train_label_vectors, e_xed, xed_eval_label_vectors, num_labels, 5)\n",
        "\n",
        "print(f\"Model: {model_name}, initial learning rate = {init_lr}, input size = {input_size}, batch size = {batch_size_train}, epochs = {epochs}\")\n",
        "print(\"\\nTDT neutrals:\")\n",
        "print_results(runs_tdt, eval_label_vectors)\n",
        "print(\"\\nXED neutrals:\")\n",
        "print_results(runs_xed, xed_eval_label_vectors)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6268d1e3cf19470f8fb075500b029a83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb6387759e2a4e4b959d661badb3fcc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=656434900.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f31a721e660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f31bea65e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f31a721e660>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f31bea65e58> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f31bc3fa8c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f31bc3fa8c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.2828"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 235s 283ms/step - loss: 0.2826 - val_loss: 0.1085\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 194s 279ms/step - loss: 0.0633 - val_loss: 0.1074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.2808"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 212s 284ms/step - loss: 0.2806 - val_loss: 0.1093\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 194s 280ms/step - loss: 0.0681 - val_loss: 0.1081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 212s 283ms/step - loss: 0.3007 - val_loss: 0.1056\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 194s 280ms/step - loss: 0.0627 - val_loss: 0.1031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.2956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 212s 283ms/step - loss: 0.2954 - val_loss: 0.1029\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 194s 280ms/step - loss: 0.0642 - val_loss: 0.1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.2854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 212s 283ms/step - loss: 0.2852 - val_loss: 0.1023\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 195s 280ms/step - loss: 0.0648 - val_loss: 0.1033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3601"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 96s 116ms/step - loss: 0.3600 - val_loss: 0.2015\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 78s 112ms/step - loss: 0.1544 - val_loss: 0.2087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 95s 115ms/step - loss: 0.3941 - val_loss: 0.2096\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 78s 112ms/step - loss: 0.1623 - val_loss: 0.2006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3624"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 94s 115ms/step - loss: 0.3622 - val_loss: 0.2080\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 78s 112ms/step - loss: 0.1561 - val_loss: 0.1981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.4131"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 95s 115ms/step - loss: 0.4130 - val_loss: 0.2055\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 77s 111ms/step - loss: 0.1656 - val_loss: 0.2035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3418"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 95s 115ms/step - loss: 0.3417 - val_loss: 0.2035\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 78s 112ms/step - loss: 0.1537 - val_loss: 0.2054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: TurkuNLP/bert-base-finnish-uncased-v1, initial learning rate = 2e-05, input size = 128, batch size = 16, epochs = 2\n",
            "\n",
            "TDT neutrals:\n",
            "Accuracy: 0.9314, 0.9381, 0.9314, 0.9398, 0.9365\n",
            "Weighted F-score: 0.8477, 0.8594, 0.8553, 0.8681, 0.8619\n",
            "Average accuracy: 0.9355, stdev: 0.0034\n",
            "Average weighted F-score: 0.8585, stdev: 0.0068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.8710    0.8617    0.8663       188\n",
            "         joy     0.8506    0.8912    0.8704       147\n",
            "\n",
            "   micro avg     0.8618    0.8746    0.8681       335\n",
            "   macro avg     0.8608    0.8764    0.8684       335\n",
            "weighted avg     0.8621    0.8746    0.8681       335\n",
            " samples avg     0.2437    0.2446    0.2439       335\n",
            "\n",
            "\n",
            "XED neutrals:\n",
            "Accuracy: 0.8403, 0.8503, 0.8562, 0.8487, 0.8453\n",
            "Weighted F-score: 0.6773, 0.6983, 0.7112, 0.7003, 0.6890\n",
            "Average accuracy: 0.8482, stdev: 0.0053\n",
            "Average weighted F-score: 0.6952, stdev: 0.0114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7107    0.6011    0.6513       188\n",
            "         joy     0.7800    0.7959    0.7879       147\n",
            "\n",
            "   micro avg     0.7443    0.6866    0.7143       335\n",
            "   macro avg     0.7453    0.6985    0.7196       335\n",
            "weighted avg     0.7411    0.6866    0.7112       335\n",
            " samples avg     0.1906    0.1919    0.1909       335\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-zKGDywGI7Y",
        "outputId": "0b830b86-fcf6-4c9c-c70b-e32b1c733c72"
      },
      "source": [
        "# Evaluate with out-of-domain data\n",
        "\n",
        "# Writes a list of predictions (raw probability) for both models to a file for further processing.\n",
        "# Also creates a file with just the predictions that differ between the models.\n",
        "\n",
        "import csv\n",
        "\n",
        "ood_texts = load_fields(twitter_and_s24_fn)[1][1:]\n",
        "\n",
        "ood_encodings = tokenizer(ood_texts, truncation=True, padding='longest', max_length=input_size)\n",
        "\n",
        "e_ood = [tf.constant(ood_encodings.data[s]) for s in ['input_ids', 'attention_mask', 'token_type_ids']]\n",
        "\n",
        "def print_agreement_results(pred1, pred2):\n",
        "  accuracy = accuracy_score(pred1, pred2)\n",
        "  weighted_f1 = f1_score(pred1, pred2, average='weighted')\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "  print(f\"Weighted F-score: {weighted_f1}\")\n",
        "  print(f\"Reverse F-score: {f1_score(pred2, pred1, average='weighted')}\")\n",
        "\n",
        "def list_labels(l):\n",
        "  return [i for i, v in enumerate(l) if v]\n",
        "\n",
        "def write_disagreement(texts, pred1, pred2):\n",
        "  incorrect = [t for t in zip(texts, pred1, pred2) if t[1] != t[2]]\n",
        "  print(incorrect[:5])\n",
        "  with open(disagreement_fn, 'wt') as file:\n",
        "    tsv_writer = csv.writer(file, delimiter='\\t')\n",
        "    tsv_writer.writerow(('text', 'tdt_neutrals', 'xed_neutrals'))\n",
        "    for t in incorrect:\n",
        "      tsv_writer.writerow(t)\n",
        "\n",
        "def write_all(texts, pred1, pred2):\n",
        "  all = [(text, p1[0], p1[1], p2[0], p2[1]) for text, p1, p2 in zip(texts, pred1, pred2)]\n",
        "  print(all[:5])\n",
        "  first = index_to_name[encoded_to_index[0]]\n",
        "  second = index_to_name[encoded_to_index[1]]\n",
        "  with open(probabilities_fn, 'wt') as file:\n",
        "    tsv_writer = csv.writer(file, delimiter='\\t')\n",
        "    tsv_writer.writerow(('text', 'tdt_neutral_'+first, 'tdt_neutral_'+second, 'xed_neutral_'+first, 'xed_neutral_'+second))\n",
        "    for t in all:\n",
        "      tsv_writer.writerow(t)\n",
        "\n",
        "def pred_to_list(pred):\n",
        "  return [','.join(n) if n else 'neutral' for n in [[index_to_name[encoded_to_index[e]] for e in list_labels(l)] for l in pred]]\n",
        "\n",
        "runs_tdt = train_evaluate(t, train_label_vectors, e_ood, None, num_labels, 1)[0]\n",
        "runs_xed = train_evaluate(t_xed, xed_train_label_vectors, e_ood, None, num_labels, 1)[0]\n",
        "pred_tdt = (tf.math.sigmoid(runs_tdt) >= 0.5).numpy().tolist()\n",
        "pred_xed = (tf.math.sigmoid(runs_xed) >= 0.5).numpy().tolist()\n",
        "list_tdt = pred_to_list(pred_tdt)\n",
        "list_xed = pred_to_list(pred_xed)\n",
        "\n",
        "print(f\"Model: {model_name}, initial learning rate = {init_lr}, input size = {input_size}, batch size = {batch_size_train}, epochs = {epochs}\")\n",
        "print_agreement_results(pred_tdt, pred_xed)\n",
        "write_disagreement(ood_texts, list_tdt, list_xed)\n",
        "write_all(ood_texts, tf.math.sigmoid(runs_tdt).numpy().tolist(), tf.math.sigmoid(runs_xed).numpy().tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r695/695 [==============================] - 325s 448ms/step - loss: 0.3165 - val_loss: 0.0000e+00\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 309s 445ms/step - loss: 0.0694 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at TurkuNLP/bert-base-finnish-uncased-v1 and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - ETA: 0s - loss: 0.3943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "695/695 [==============================] - 124s 157ms/step - loss: 0.3941 - val_loss: 0.0000e+00\n",
            "Epoch 2/2\n",
            "695/695 [==============================] - 107s 154ms/step - loss: 0.1535 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: TurkuNLP/bert-base-finnish-uncased-v1, initial learning rate = 2e-05, input size = 128, batch size = 16, epochs = 2\n",
            "Accuracy: 0.6820749871597329\n",
            "Weighted F-score: 0.4577206191992184\n",
            "Reverse F-score: 0.45747934830104664\n",
            "[('vai onko taas, ettei heitÃ¤ saa sakottaa, kun he tuovat imatralle niin paljon rahaa.......', 'neutral', 'anger'), ('Varsin hyvin kuvaava henkilÃ¶kuva tietynlaisesta miehestÃ¤, joka pitÃ¤Ã¤ nÃ¤htÃ¤vÃ¤sti itseÃ¤Ã¤n unelmamiehenÃ¤.', 'neutral', 'joy'), ('Valitettavasti.', 'anger', 'neutral'), ('YmpÃ¤ristÃ¶tukea pitÃ¤Ã¤ myÃ¶ntÃ¤Ã¤ sen mukaan, mitkÃ¤ ovat tuen myÃ¶ntÃ¤misen perusteet.', 'neutral', 'anger'), ('Perusteisiin tuskin kuuluu se, ettÃ¤ joku tekee kauppoja suomalaisen (=Suomessa sijaitsevan) telakkateollisuuden kanssa.', 'neutral', 'anger')]\n",
            "[('No kuka hel-vetti sinnekin muka on menossa?', 0.9003850817680359, 0.008050990290939808, 0.7383602261543274, 0.006663632579147816), ('Eilen noin klo 18 poliisien siiviiliskoda ajeli tutkan kanssa pietarintietÃ¤ edestakaisin rajalle ja takaisin ja useat vanjat paineli reipasta ylinopeutta yhtÃ¤ ja kahta kaistaa sinnepÃ¤in, mutta ihmetyksekseni ei mitÃ¤Ã¤n reaktiota vaikka skoda ajeli vastaan heitÃ¤ !!!', 0.005661400500684977, 0.00275915814563632, 0.13848616182804108, 0.03966628387570381), ('tietÃ¤Ã¤kÃ¶ kukaan onkohan vanjat saaneet tÃ¤Ã¤llÃ¤ yhtÃ¤Ã¤n kertaa ylinopeussakkoja tai sakkoja yleensÃ¤kÃ¤Ã¤n ??', 0.01046256348490715, 0.0029517554212361574, 0.016931787133216858, 0.00738328555598855), ('vai onko taas, ettei heitÃ¤ saa sakottaa, kun he tuovat imatralle niin paljon rahaa.......', 0.29257088899612427, 0.004879394080489874, 0.9594123959541321, 0.03367004171013832), ('olen kyllÃ¤ nÃ¤hnyt useamman kerran kun suomi -autoja seisoo pietarintien tienposkessa poliisien \"jututettavina\".', 0.004720217082649469, 0.0025961168576031923, 0.0304617490619421, 0.009989147074520588)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
